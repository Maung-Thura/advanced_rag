{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkzRyN4t06mL",
        "outputId": "794c9be6-4083-4a74-cc02-58b3ac15b359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.33)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.44)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.44)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.48)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain_community) (2.6.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.43->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain_community) (2.16.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.44)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.21.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.1.48)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Collecting PyPDF2<3.0\n",
            "  Downloading pypdf2-2.12.1-py3-none-any.whl (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "  Attempting uninstall: PyPDF2\n",
            "    Found existing installation: PyPDF2 3.0.1\n",
            "    Uninstalling PyPDF2-3.0.1:\n",
            "      Successfully uninstalled PyPDF2-3.0.1\n",
            "Successfully installed PyPDF2-2.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U  langchain\n",
        "!pip install -U langchain_community\n",
        "!pip install -U langchain_openai\n",
        "!pip install 'PyPDF2<3.0'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "import requests\n",
        "import PyPDF2\n",
        "import io\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "KwHE83j823Lq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_remote_file(url, local_filename):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"File downloaded and saved as {local_filename}\")\n",
        "    else:\n",
        "        print(\"Failed to download file:\", response.status_code)"
      ],
      "metadata": {
        "id": "oW_EsQ_ZKA5q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://proceedings.mlr.press/v236/strieder24a/strieder24a.pdf'\n",
        "req = urllib.request.Request(URL, headers={'User-Agent' : \"Magic Browser\"})\n",
        "remote_file = urllib.request.urlopen(req).read()\n",
        "remote_file_bytes = io.BytesIO(remote_file)\n",
        "pdfdoc_remote = PyPDF2.PdfFileReader(remote_file_bytes)\n",
        "\n",
        "text = \"\"\n",
        "for i in range(pdfdoc_remote.numPages):\n",
        "    text += pdfdoc_remote.getPage(i).extractText()\n",
        "\n",
        "local_file_name = 'strieder24a.pdf'\n",
        "with open(local_file_name, 'w') as f:\n",
        "    f.write(text)\n",
        "\n",
        "text_loader = TextLoader(local_file_name)\n",
        "# Now you can use text_loader for language processing tasks\n",
        "print(\"Sample research paper loaded successfully.\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"your open api key. create one on openai.com\"\n",
        "\n",
        "# We load the document using LangChain’s handy extractors, formatters, loaders, embeddings, and LLMs\n",
        "documents = text_loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "print(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXFamLzeChsE",
        "outputId": "169c6b14-5159-47d2-d8d7-fa9fa847087a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample research paper loaded successfully.\n",
            "[Document(page_content='Proceedings of Machine Learning Research vol 236:1–15, 2024 3rd Conference on Causal Learning and Reasoning\\nDual Likelihood for Causal Inference under Structure Uncertainty\\nDavid Strieder DAVID .STRIEDER @TUM .DEand Mathias Drton MATHIAS .DRTON @TUM .DE\\nMunich Center for Machine Learning and Department of Mathematics, TUM School of Computation, Infor-\\nmation and Technology, Technical University of Munich, Germany\\nEditors: Francesco Locatello and Vanessa Didelez\\nAbstract\\nKnowledge of the underlying causal relations is essential for inferring the effect of interventions\\nin complex systems. In a widely studied approach, structural causal models postulate noisy func-\\ntional relations among interacting variables, where the underlying causal structure is then naturally\\nrepresented by a directed graph whose edges indicate direct causal dependencies. In the typical\\napplication, this underlying causal structure must be learned from data, and thus, the remaining\\nstructure uncertainty needs to be incorporated into causal inference in order to draw reliable con-\\nclusions. In recent work, test inversions provide an ansatz to account for this data-driven model\\nchoice and, therefore, combine structure learning with causal inference. In this article, we propose\\nthe use of dual likelihood to greatly simplify the treatment of the involved testing problem. Indeed,\\ndual likelihood leads to a closed-form solution for constructing confidence regions for total causal\\neffects that rigorously capture both sources of uncertainty: causal structure and numerical size of\\nnonzero effects. The proposed confidence regions can be computed with a bottom-up procedure\\nstarting from sink nodes. To render the causal structure identifiable, we develop our ideas in the\\ncontext of linear causal relations with equal error variances.\\nKeywords: linear structural causal models, graphical models, dual likelihood, causal effects, un-\\ncertainty quantification\\n1. Introduction\\nReasoning about causal relations and inferring the effect of interventions in complex systems is a\\ncentral task of scientific research. The field of causal discovery addresses this challenge with much\\nfundamental research being done over the last decades (Pearl, 2009; Spirtes et al., 2000). In particu-\\nlar, in many applied settings, access to interventional data is limited, and thus, performing classical\\ncontrolled experiments to investigate causal relations is not feasible. To tackle this problem, various\\nidentifiability results clarify under which conditions interventional distributions can theoretically\\nbe identified from observational data alone. Furthermore, many structure learning algorithms have\\nbeen proposed that estimate causal structures using only observed data. On the other hand, when the\\nunderlying causal structure is known, causal inference results enable researchers to estimate causal\\nquantities in complex systems and assess remaining uncertainty. However, when the underlying\\ncausal structure is learned from data, the remaining structure uncertainty needs to be incorporated\\ninto causal inference in order to draw reliable conclusions.\\nRecently, Strieder et al. (2021) introduced a first ansatz for constructing confidence regions for\\ncausal effects that account for both types of uncertainty, uncertainty about the causal structure and\\nuncertainty about the numerical size of the effect. They consider bivariate linear structural causal\\nmodels (SCMs) and develop a solution based on test inversion. Their strategy was improved and\\ngeneralized to higher-dimensional linear SCMs in Strieder and Drton (2023). In this work, we\\n© 2024 D. Strieder & M. Drton.236:\\n1–17\\n, 2024\\nSTRIEDER DRTON\\ntake up their idea of using a test inversion ansatz to construct confidence regions for total causal\\neffects (see Section 2). However, in contrast to the earlier work, we suggest here to employ dual\\nlikelihood for the arising testing problem. An important consequence of the use of dual likelihood\\nis that we are able to provide a closed-form solution for our proposed confidence regions (Section 3)\\nand can, thus, avoid the numerical optimization algorithms deployed by Strieder and Drton (2023).\\nFurthermore, while the earlier methods rely on a top-down procedure starting from the source node,\\nby employing dual likelihood, we obtain a bottom-up procedure starting from the sink node. Thus,\\nour proposed dual likelihood method provides an interesting alternative perspective on strategies\\nto save on computation. Finally, in Section 4.2, we present computational details and analyze the\\nperformance in a simulation study. Further simulation results can be found in Appendix A. In the\\nconcluding Section 5, we discuss extensions and possible future work.\\n2. Background\\nA common tool for studying causal relationships among interacting variables are structural causal\\nmodels (Peters et al., 2017; Maathuis et al., 2019), where each variable is represented as a function\\nof other variables (its causes) and a random error term. The causal perspective views these relation-\\nships as assignments rather than mathematical equations, and thus, changes in the causes result in\\nchanges in the effects but not vice versa, reflecting the inherent asymmetry in cause-effect relation-\\nships. In this section, we review a restricted class of causal models, namely linear structural causal\\nmodels with Gaussian errors and equal error variances (Peters and B ¨uhlmann, 2014), as well as the\\ndefinition of the total causal effect, which is the causal target of interest in this study. Further, we\\nreview the test inversion ansatz introduced by Strieder et al. (2021) to construct confidence regions\\nfor causal effects that account for structure uncertainty.\\n2.1. Causal Effects in Linear Structural Causal Models\\nWe assume access to observational data in the form of nindependent copies of a random vector\\nX= (X1, ..., X d)with zero mean. To ensure unique identifiability, we follow a line of research\\nintroduced by Peters and B ¨uhlmann (2014) that focuses on linear relations and normal distributed\\nerrors with equal variances, represented by the equation system\\nXj=X\\ni̸=jβj,iXi+εj, j = 1, . . . , d, (1)\\nwhere B:= [βj,i]d\\nj,i=1represents the direct causal effects between variables, and εjare independent,\\nnormally distributed error terms with common variance σ2. Such a linear structural causal model is\\nnaturally represented by a directed graph, where a missing edge i→jindicates no direct effects,\\nthat is, bj,i= 0. Further, we assume the underlying graph to be acyclic, which entails the unique\\nsolution X= (Id−B)−1εof the equation system (1), where Iddenotes the d×didentity matrix.\\nThe corresponding covariance matrix is given by Σ =σ2(Id−B)−1(Id−B)−T.\\nIn the remainder of the article, we use the following notation and graphical concepts. We write\\ni <Gjif node iprecedes node jin a causal ordering of the corresponding directed acyclic graph\\n(DAG). If the DAG contains an edge from node ito node j, then node iis called a parent of node\\nj, and we denote the set of all parents of node jwithp(j). Further, if the DAG contains a directed\\npath from node ito node j, then node jis called a descendant of node i, and we denote the set of\\n22\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nall descendants of node iwithd(i). Finally, we write Σj,i|p(i)for the conditional covariance matrix,\\nthat is,\\nΣj,i|p(i):= Σ j,i−Σj,p(i)(Σp(i),p(i))−1Σp(i),i.\\nOur aim is to estimate the total causal effect C(i→j)in linear SCMs and rigorously quantify\\nthe remaining uncertainty. Formally, the total causal effect is defined as the unit change in the\\nexpectation of Xjwith respect to an intervention in Xi\\nC(i→j) :=d\\ndxiE[Xj|do(Xi=xi)] = Σ j,i|p(i)(Σi,i|p(i))−1.\\nWhile this parameter of interest is given as a simple function of the covariance matrix, difficulties\\narise in practice when the underlying causal structure is unknown. In such situations, the condi-\\ntioning set is unknown and has to be inferred from data, which introduces structure uncertainty.\\nWe emphasize that due to the identifiability of Gaussian SCMs with equal error variances (e.g.,\\nChen et al., 2019; Ghoshal and Honorio, 2018), estimating the total causal effect is nevertheless a\\nwell-defined problem.\\nA naive two-step approach that treats the two tasks of causal discovery and causal inference\\nseparately by learning the causal structure first and then calculating confidence intervals in the in-\\nferred model does not account for uncertainty in the structure. Furthermore, classical bootstrapping\\nmethods also fail to correctly account for model uncertainty due to singularities at the intersection\\nof models. To address this issue, Strieder et al. (2021) introduced a framework for constructing\\nconfidence intervals that rigorously account for structure uncertainty, which was then generalized\\nin Strieder and Drton (2023). However, thoroughly accounting for structure uncertainty proves a\\nchallenging task, given the enormous number of possible structures, even in moderate dimensions.\\n2.2. Confidence Intervals via Test Inversion\\nThe main idea is to leverage the classical duality between statistical hypothesis tests and confidence\\nregions (Casella and Berger, 1990). To this end, we consider all possible causal structures in the\\nfollowing way. If we perform valid hypothesis tests for all attainable causal effects, then all values\\nthat cannot be rejected form a confidence region for the total causal effect. This shifts the task to\\nconstructing suitable hypothesis tests for all attainable causal effects.\\nUnder the assumption of an underlying linear structural causal model with equal error variances,\\nevery possible distribution N(0,Σ)is given by a set of covariance matrices M:=S\\nG∈G(d)M(G),\\nwhere G(d)is the set of all possible complete DAGs on dnodes and\\nM(G) =n\\nΣ∈PD(d) :∃σ2>0withσ2= Σ k,k|p(k)∀k= 1, . . . , do\\n.\\nHere, we write PD (d)for the cone of positive definite d×dmatrices. The hypothesis of a fixed\\ncausal effect C(i→j)of size ψfurther restricts the set of possible distributions, where the specific\\nstructure of the constraint depends on the DAG G. Thus, with\\nMψ(G) :=n\\nΣ∈PD(d) :∃σ2>0withψσ2= Σ j,i|p(i)andσ2= Σ k,k|p(k)∀k= 1, . . . , do\\n,\\n(2)\\nandMψ:=S\\nG∈G(d)Mψ(G), the task is to invert the statistical testing problem\\nH(ψ)\\n0: Σ∈ M ψagainst H1: Σ∈ M\\\\M ψ (3)\\nfor all ψ∈R.\\n33\\nSTRIEDER DRTON\\n3. Testing for Total Causal Effects with the Dual Likelihood\\nEarlier methods (Strieder and Drton, 2023) propose to use constrained likelihood ratio tests for the\\ntesting problem (3). However, the direct maximization of the Gaussian likelihood with constraints\\non the total causal effect has no closed-form solution, which leads to algorithms that rely on nu-\\nmerical optimization routines and grid searches. Instead, our proposal is to employ dual likelihood\\ntheory for Gaussian models (e.g., Brown, 1986; Kauermann, 1996) to solve the testing problem (3)\\nand, thus, obtain a simple closed-form solution.\\nTo obtain our main result, we first introduce the dual likelihood for Gaussian graphical models.\\nMaximizing the Gaussian likelihood corresponds to the minimization problem\\narg min\\nΣ∈MKL(PbΣ, PΣ) = arg min\\nΣ∈M\\x00\\ntr(Σ−1bΣ) + log det(Σ)\\x01\\n,\\nwhere KL is the Kullback–Leibler divergence with sample covariance bΣ. As the Kullback–Leibler\\ndivergence is not symmetrical in its arguments, the minimization problem\\narg min\\nΣ∈MKL(PΣ, PbΣ) = arg min\\nΣ∈M\\x00\\ntr(bΣ−1Σ)−log det(Σ)\\x01\\n= arg min\\nΣ∈M\\x00\\ntr(ΣbΣ−1) + log det(Σ−1)\\x01\\nyields a different estimator, the dual maximum likelihood estimator. Along similar lines, the dual\\n(log-)likelihood of Σfor the observed parameter bΣ−1is defined as\\n2\\nnℓdual\\nn(Σ|bΣ−1) :=−log det(2 πΣ−1)−tr(ΣbΣ−1).\\nWe note that this dual likelihood is reciprocal to the Gaussian likelihood in the sense that for ob-\\nserved sample covariance bΣ−1, we have\\nℓdual\\nn(Σ|bΣ−1) =ℓn(Σ−1|bΣ−1), (4)\\nwhere2\\nnℓn(Σ|bΣ) := −log det(2 πΣ)−tr(Σ−1ˆΣ).\\n3.1. Dual Likelihood Ratio Test\\nIn order to construct confidence intervals for the total causal effects, our idea is to invert dual likeli-\\nhood ratio tests of the testing problem (3) with the dual likelihood ratio test statistic\\ndual-ˇλ(ψ)\\nn: = 2\\x10\\nsup\\nΣ∈Mℓdual\\nn(Σ|bΣ−1)−sup\\nΣ∈Mψℓdual\\nn(Σ|bΣ−1)\\x11\\n(5)\\n= 2\\x10\\nsup\\nΣ∈Mℓn(Σ−1|bΣ−1)−sup\\nΣ∈Mψℓn(Σ−1|bΣ−1)\\x11\\n.\\nFirst, we observe that by employing equation (4), this dual likelihood ratio test statistic equals the\\nclassical likelihood ratio test statistic for a modified problem. More precisely, we redefine the model\\nspaceM−1:=S\\nG∈G(d)M−1(G)with\\nM−1(G) :=n\\nΩ∈PD(d) :∃˜σ2>0with˜σ2= Ω k,k|d(k)∀k= 1, . . . , do\\n,\\n44\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nwhere Ω = Σ−1. Similarly, we redefine the hypothesis space M−1\\nψ=S\\nG∈G(d)M−1\\nψ(G)with\\nM−1\\nψ(G) :=n\\nΩ∈PD(d) :∃˜σ2>0with˜σ2= Ω k,k|d(k)∀k= 1, . . . , d\\nandψ=τj\\x00\\nΩi,d(i)(Ωd(i),d(i))−1\\x01o\\n,\\nwhere τjprojects the |d(i)|-dimensional vector onto the component corresponding to jifj∈d(i)\\nand zero otherwise. Then, we obtain the following Lemma.\\nLemma 1 LetΣ∈PD(d). Then the following equivalences hold.\\n1.Σ∈ M if and only if Σ−1∈ M−1.\\n2.Σ∈ M ψif and only if Σ−1∈ M−1\\nψ.\\nProof This result follows from straightforward calculations using the following observation. If\\nΣ = σ2(Id−B)−1(Id−B)−Tfor some DAG Gwith edge weights Band equal error variance\\nσ2>0, then Σ−1=σ−2(Id−T)−1(Id−T)−T, where Trepresents the negative total causal effect\\nbetween variables. Thus, Σ−1corresponds to the covariance matrix of a DAG G′, where the parent\\nsetsp(i)inG′are the descendants d(i)inGfor all i= 1, . . . , d , the edge weights are given by T\\nand equal error variance σ−2. Constraints on the total causal effects in ΣandGthus correspond to\\nconstraints on direct effects in Σ−1andG′.\\nUsing Lemma 1, we immediately obtain that the dual likelihood ratio test statistic (5) corre-\\nsponds to\\ndual-ˇλ(ψ)\\nn= 2\\x10\\nsup\\nΩ∈M−1ℓn(Ω|bΣ−1)−sup\\nΩ∈M−1\\nψℓn(Ω|bΣ−1)\\x11\\n,\\nwhich is the classical likelihood ratio test statistic for the modified testing problem\\n˜H(ψ)\\n0: Ω∈ M−1\\nψagainst ˜H1: Ω∈ M−1\\\\M−1\\nψ, (6)\\nwith observed sample covariance bΣ−1. Thus, we can employ similar strategies to Strieder and Drton\\n(2023) in order to obtain confidence regions for total causal effects.\\n3.2. Confidence Intervals with Dual Likelihood\\nIn this subsection, we state our main result, a confidence region for total causal effects C(i→j)\\nthat captures structure uncertainty as well as uncertainty about the numerical size of the effect. Our\\nfirst step to tackle the testing problem (6) is to relax the alternative M−1and employ the theory of\\nintersection union tests, see e.g. Casella and Berger (1990), to obtain a simple upper bound on the\\ndistribution of the dual likelihood ratio test statistic via\\ndual-ˇλ(ψ)\\nn≤dual-λ(ψ)\\nn(G) := 2\\x10\\nsup\\nΩ∈PD(d)ℓn(Ω|bΣ−1)− sup\\nΩ∈M−1\\nψ(G)ℓn(Ω|bΣ−1)\\x11\\n.\\nFurther, we define dual- ˇλ(ψ)\\nn(i <Gj) := min G∈G(d) :i<Gjdual-ˇλ(ψ)\\nn(G), where\\ndual-ˇλ(ψ)\\nn(G) := 2\\x10\\nsup\\nΩ∈M−1ℓn(Ω|bΣ−1)− sup\\nΩ∈M−1\\nψ(G)ℓn(Ω|bΣ−1)\\x11\\n.\\n55\\nSTRIEDER DRTON\\nThen we obtain our following main result via test inversions of asymptotically conservative\\nhypothesis test based on the asymptotic distribution of the upper bound dual- λ(ψ)\\nn(G)under every\\nsingle hypothesis M−1\\nψ(G), see Lemma 3, as well as the closed-form solution of the dual likelihood\\nestimation under constraints on the total causal effect, see Section 3.3.\\nTheorem 2 Letα∈(0,1). Then an asymptotic (1−α)-confidence set for the total causal effect\\nC(i→j)is given by\\nC:={ψ∈R:dual-ˇλ(ψ)\\nn(i <Gj)≤χ2\\nd,1−α} ∪ {0 :dual-ˇλ(0)\\nn(j <Gi)≤χ2\\nd−1,1−α}.\\nThis confidence set can be constructed explicitly as follows. Define\\nK:= min\\nG∈G(d)dX\\nk=1(bΣ−1)k,k|d(k), Z := min\\nG∈G(d):j<GidX\\nk=1(bΣ−1)k,k|d(k),\\nand for all G∈ G(d)withi <Gj,\\nDG:= (bΣ−1)2\\ni,j|d(i)\\\\{j}−(bΣ−1)j,j|d(i)\\\\{j}\\x10dX\\nk̸=i(bΣ−1)k,k|d(k)+(bΣ−1)i,i|d(i)\\\\{j}−Kexp\\x00χ2\\nd,1−α\\ndn\\x01\\x11\\n.\\nMoreover, for DG≥0, define\\nLG:=−(bΣ−1)i,j|d(i)\\\\{j}−√DG\\n(bΣ−1)j,j|d(i)\\\\{j}, U G:=−(bΣ−1)i,j|d(i)\\\\{j}+√DG\\n(bΣ−1)j,j|d(i)\\\\{j}.\\nThen the closed-form solution for the confidence set Cis given by\\nC=[\\nG∈G(d):DG≥0\\x02\\nLG, UG\\x03[\\x08\\n0 :Z≤Kexp\\x00χ2\\nd−1,1−α\\ndn\\x01\\t\\n.\\nProof Letψ∈RandΣ∈ M ψ. Since Mψ=S\\nG∈G(d)Mψ(G)there exists a complete graph G,\\nsuch that Σ∈ M ψ(G). Ifi <Gj, it follows with the introduced upper bound and Lemma 3\\nPΣ\\x10\\ndual-ˇλ(ψ)\\nn> χ2\\nd,1−α\\x11\\n≤PΣ\\x10\\ndual-λ(ψ)\\nn(G)> χ2\\nd,1−α\\x11\\n→α.\\nFurthermore, plugging in the dual likelihood estimates (7) and (8) derived in Section 3.3, we view\\ndual-ˇλ(ψ)\\nn(G)−χ2\\nd,1−α= 2\\x10\\nsup\\nΩ∈M−1ℓn(Ω|bΣ−1)− sup\\nΩ∈M−1\\nψ(G)ℓn(Ω|bΣ−1)\\x11\\n−χ2\\nd,1−α\\nas a strictly convex quadratic polynomial in ψ. With K:= min G∈G(d)Pd\\nk=1(bΣ−1)k,k|d(k)and\\nDG:= (bΣ−1)2\\ni,j|d(i)\\\\{j}−(bΣ−1)j,j|d(i)\\\\{j}\\x10dX\\nk̸=i(bΣ−1)k,k|d(k)+(bΣ−1)i,i|d(i)\\\\{j}−Kexp\\x00χ2\\nd,1−α\\ndn\\x01\\x11\\n,\\n66\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nthis quadratic polynomial has real roots if DG≥0. Thus, the inequality dual- ˇλ(ψ)\\nn(G)≤χ2\\nd,1−α\\nholds if and only if\\nψ∈\"\\n−(bΣ−1)i,j|d(i)\\\\{j}−√DG\\n(bΣ−1)j,j|d(i)\\\\{j},−(bΣ−1)i,j|d(i)\\\\{j}+√DG\\n(bΣ−1)j,j|d(i)\\\\{j}#\\n.\\nWe obtain an analogous result for j <Gi, and the test inversion approach yields the claim.\\nNote that for non-zero effects, we do not need to test among graphs with j <Gi. Thus, our\\nconfidence regions may consist of a non-zero interval and an isolated zero, reflecting the remaining\\nuncertainty about the direction of the causal relation. In contrast, for zero-sized effects, we need to\\nconsider all causal orderings since multiple paths might cancel.\\nOur main result employs the following asymptotic distribution of the upper bound dual- λ(ψ)\\nn(G)\\nunder every single hypothesis M−1\\nψ(G).\\nLemma 3 LetG∈ G(d)be a DAG and let ψ∈R. Then, the relaxed dual likelihood ratio test\\nstatistic dual-λψ\\nn(G)satisfies one of the following properties.\\na) If i <Gj, then under the hypothesis H(ψ)\\n0(G)\\ndual-λ(ψ)\\nn(G)D→χ2\\nd.\\nb) If j <Gi, then under the hypothesis H(0)\\n0(G)\\ndual-λ(0)\\nn(G)D→χ2\\nd−1.\\nProof We assume i <Gj. Without loss of generality, let (1,2, . . . , d )be the causal ordering of G.\\nThenM−1\\nψ(G) ={Ω∈PD(d) :fψ(Ω|G) = 0}, with\\nfψ(Ω|G) :=\\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8edτj(Ωi,{i+1,...,d}(Ω{i+1,...,d},{i+1,...,d})−1)−ψ\\nΩ1,1|{2,...,d}−Ωd,d\\n...\\nΩd−1,d−1|d−Ωd,d\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f8.\\nThe Jacobian of fψhas full rank d, which follows due to its (nonzero) triangular structure in\\nderivatives for Ωk,kfor all k= 1, . . . , d −1, while the first row has nonzero derivative for Ωi,j\\nbut zero derivatives for Ωk,kfor all k= 1, . . . , i . Thus, M−1\\nψ(G)defines a1\\n2(d2−d)-dimensional\\nsubmanifold of R1\\n2(d2+d). The case j < Gifollows similarly, and thus, the claim follows. For\\ndetails, we refer to Drton (2009).\\nNote that the constraint of a zero-sized effect does not restrict the submanifold M−1\\n0(G)for\\nj < Gi. All edge weights in the corresponding linear SCMs can vary freely, and thus, the two\\ndifferent degrees of freedom for the chi-square limits arise.\\n77\\nSTRIEDER DRTON\\n3.3. Dual Likelihood Estimation\\nMaximizing the classical Gaussian likelihood under constraints on total causal effects leads to com-\\nplex optimization problems with polynomial constraints that need to be solved with numerical op-\\ntimization routines. In contrast to that, we can explicitly maximize the dual likelihood under con-\\nstraints on total causal effects. Thus, as an important consequence of the use of dual likelihood, we\\nare able to provide a closed-form solution for our proposed confidence regions in Theorem 2.\\nIn order to derive this closed-form solution, we need to calculate the dual likelihood ratio test\\nstatistic (5). This involves maximizing the dual likelihood in two cases, the unrestricted case Σ∈\\nM, and under the constraint of a fixed-size total causal effect Σ∈ M ψ. In the following, we solve\\nthe dual likelihood equations for a fixed graph G. In order to consider full uncertainty over all\\npossible causal structures, we subsequently need to cleverly optimize over the space of DAGs, see\\nSection 4.1. In the case Σ∈ M (G), we obtain\\n2\\nnsup\\nΣ∈M(G)ℓdual\\nn(Σ|bΣ−1) = sup\\nΩ∈M−1(G)−log det(2 πΩ)−tr(Ω−1ˆΣ−1)\\n= sup\\nT∈R−G,σ2>0−dlog(2πσ−2)−σ2tr\\x00\\n(I−T)T(I−T)ˆΣ−1\\x01\\n,\\nwhere R−G:={T∈Rd×d:tk,l= 0ifl /∈d(k)}. This immediately follows if we recapitulate\\nΣ =σ2(Id−B)−1(Id−B)−T=σ2(I−T)T(I−T),\\nwhere T∈R−Grepresents the negative total causal effect between variables. Maximizing over the\\nequal error variance σ2then leads to a linear least squares problem with the optimal solution\\nmin\\nT∈RGtr\\x00\\n(I−T)T(I−T)ˆΣ−1\\x01\\n=dX\\nk=1(bΣ−1)k,k|d(k). (7)\\nIn the second case of an additional constraint of a fixed size total causal effect C(i→j) =ψ,\\nwe can similarly first optimize over the equal error variance σ2to derive a linear least squares\\nproblem. That is, for Σ∈ M ψ(G), maximizing the dual likelihood then corresponds to the linear\\nleast squares problem\\nmin\\nT∈R−G,ψtr\\x00\\n(I−T)T(I−T)ˆΣ−1\\x01\\n.\\nHere, the search space is additionally restricted by the fixed size total causal effect C(i→j) =ψ\\nand given by R−G,ψ:={T∈Rd×d:tk,l= 0 ifl /∈d(k), ti,j=−ψ}. Solving this linear least\\nsquares problem with the constraint of one fixed parameter leads to the solution\\ndX\\nk̸=i(bΣ−1)k,k|d(k)+ (bΣ−1)i,i|d(i)\\\\{j}+ψ2(bΣ−1)j,j|d(i)\\\\{j}+ 2ψ(bΣ−1)i,j|d(i)\\\\{j}. (8)\\nNote that maximizing dual likelihood under constraints on total causal effects corresponds with\\nthe reciprocal property (4) to maximizing classical Gaussian likelihood under modified constraints\\non direct causal effects. Thus, while directly maximizing the classical Gaussian likelihood under\\nconstraints on the total causal effect is complicated due to the arising polynomial constraint on the\\nparameters, we are able to obtain a closed-form solution for the maximum dual likelihood estimate\\nsince the constraint only pertains to one parameter.\\n88\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\n4. Computation of Confidence Regions for Total Causal Effects\\nIn the following section, we present important computational shortcuts as well as the results of a\\nsimulation study that analyzes the performance and computation times of our proposed confidence\\nregions.\\n4.1. Computational Shortcuts\\nOur proposal of employing the dual likelihood to construct confidence regions for total causal effects\\nresolves the need for numerical optimization routines of earlier methods and leads to a closed-\\nform solution that significantly reduces computation times (see Figure 3). However, the bottleneck\\nof the task itself is the superexponential growth of the number of possible causal structures with\\nthe number of nodes. Without any knowledge about the underlying causal relation, we have to\\nconsider all possible causal structures in order to make calibrated confidence statements that include\\nthe structure uncertainty. This, already at the scale of systems with 12involved variables, entails\\naccounting for more than 1026possible graphs. Using combinatorial shortcuts that quickly reduce\\nthe search space of plausible causal structures is thus extremely important to compute confidence\\nregions that solve this task.\\nFirst, we highlight that with our methodology, we only need to consider complete DAGs, thus\\nreducing the search space to dfactorial structures for dinvolved variables. Namely, we have to\\nsearch through all permutations of dnodes, which then correspond to all possible topological order-\\nings of the involved variables. Furthermore, we employ a branch and bound type search algorithm\\nto quickly reduce the space of plausible causal orderings before performing the testing procedure\\nfor all possible causal effects ψ∈R. The main idea of this procedure in order to immediately reject\\nimplausible causal orderings is the following. We quickly approximate the maximum dual likeli-\\nhood under the alternative Ω∈ M−1with the dual likelihood estimate (7) under the causal ordering\\nobtained via recursively minimizing (bΣ−1)k,k|d(k)starting from the sink node. Then, recursively\\nstarting from the sink node, we search through the space of causal orderings in reverse and reject a\\npartial ordering if the unrestricted partial dual likelihood estimate (7) already exceeds the threshold\\nof the alternative. This is possible because the dual likelihood estimate (7) collapses into subprob-\\nlems which only depend on descendants. Moreover, looking at (8), the specific ordering among\\nthe descendants of iis not relevant for the subsequent testing procedure for the precise total causal\\neffects ψ∈R. Therefore, in our branch and bound type search algorithm, it suffices to proceed with\\nthe partial ordering that achieves the highest dual likelihood among all plausible orderings with the\\nsame set of descendants d(i). More specifically, at each step of our algorithm, we reject all partial\\norderings that do not achieve the highest dual likelihood among all plausible partial orderings of the\\nsame set of nodes and do not include i.\\nCombined, all these computational shortcuts vastly improve computation times and lead to a\\nbottom-up procedure that allows us to compute the proposed confidence region in a reasonable time\\nfor moderate dimensions, see Section 4.2. We emphasize that considering the fast superexponen-\\ntial growth of the number of possible DAGs with the number of nodes, rigorously accounting for\\nstructure uncertainty over all DAGs is an intrinsically difficult task already in moderate dimensions.\\nFurther, we highlight the interesting distinction to the LRT-method of Strieder and Drton (2023),\\nthat by employing dual likelihood, our method leads to a bottom-up procedure, starting from the\\nsink node, while their method is a top-down procedure, starting from the source node.\\n99\\nSTRIEDER DRTON\\n4.2. Simulation Study\\nIn the following simulation study, we compare the width of the proposed confidence region as well\\nas the computation times to the LRT-method by Strieder and Drton (2023). For more simulation\\nresults, we refer the reader to the Appendix A. Our experiments are designed as follows. We gener-\\nate1000 synthetic data sets based on linear SCMs corresponding to randomly selected DAGs. The\\nedge weights are sampled from a normal distribution N(β,0.1), and the error terms are sampled\\nfrom a standard normal distribution. Then we compute the confidence regions for the total causal\\neffectC(1→2)with confidence level α= 0.05. We repeat this procedure for a range of different\\naverage direct effect strengths β, sample sizes n, dimensions d, sparse or dense graphs, and for true\\nnon-zero total effects as well as for no total effect.\\nFirst, we note that the theoretical coverage guarantees of our proposed confidence regions are\\nbased on (conservative) asymptotic critical values. Nevertheless, the confidence regions achieve\\nthe desired coverage in all our simulation settings, even in low sample sizes. We explore this in\\nTable 1 in the Appendix A, which shows the empirical coverage frequencies against the sample size.\\nFurthermore, while the employed dual likelihood estimators are asymptotically efficient in the sense\\nof having the same asymptotic variance as ordinary maximum likelihood estimates, differences in\\nfinite samples are possible. Thus, we compare the performance of our confidence regions to the\\nexisting maximum likelihood approach. In Figure 1, we compare the average width of the non-\\nzero part of the confidence regions, reflecting the remaining uncertainty about the numerical size\\nof the effect. We show the results for d= 10 andβ= 0.5against the sample size. The main\\nobservation is that the difference in performance between both methods seems negligible. Similar\\nobservations can be made for other performance measures, which we defer to the Appendix A. For\\nexample, we investigate how often the zero is included in the confidence regions when there is a\\ntrue nonzero effect and observe no significant differences. Thus, both methods seem to be equally\\nconclusive about the existence as well as the numerical size of the total causal effects. Further,\\nthe two methods also perform similarly under model misspecification of equal error variances and\\nlinearity.\\nHowever, the big advantage of the proposed dual likelihood method is the significantly reduced\\ncomputation time. Employing the dual likelihood avoids time-consuming numerical optimization\\nroutines, and we immensely benefit from the closed-form solution calculated in Theorem 2. Figure\\n2 shows the computation times for β= 0.5and sample size 1000 against the dimension. Our pro-\\nposed confidence regions are faster to compute by a factor of up to 102, without any compromises\\nin terms of information value. This is even more apparent in Figure 3, which compares the compu-\\ntation times for β= 0.1and sample size 1000 against the dimension. In this setting, the generated\\ndata encompasses more structure uncertainty, given the lower average edge strength. Thus, the time\\ndifference between repeatedly applying numerical optimization algorithms versus directly comput-\\ning the closed-form solution is more fatal, such that we are not able to compute the LRT-confidence\\nregions in a reasonable time in dimensions beyond d= 8. In contrast, the computation times of our\\nproposed method seem to vary less with the amount of structure uncertainty inherent in the data set.\\nFurthermore, we highlight the observation that dense systems generally lead to wider confidence\\nregions compared to sparse systems. Intuitively, for dense graphs more paths contribute to the total\\ncausal effects on average, and thus, more uncertainty about the numerical size of the effect remains\\nin the data. In contrast, data generated by sparse DAGs generally exhibits more uncertainty about\\nthe underlying causal structure, which explains the observed increased computation times.\\n1010\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nTRUE EFFECT NO TRUE EFFECT\\n500 1000 1500 2000500 1000 1500 20000.00.30.60.91.2\\nsample sizeaverage widthLRT\\nDualLRT\\nsparse\\ndense\\nFigure 1: Mean width of 95%-confidence regions for the total causal effect in randomly generated\\n10-dim. DAGs (1000 replications).\\nTRUE EFFECT NO TRUE EFFECT\\n3 6 9 123 6 9 121e−011e+011e+03\\ndimensiontime in sec (log scale)LRT\\nDualLRT\\nsparse\\ndense\\nFigure 2: Mean computation times of 95%-confidence regions for the total causal effect in ran-\\ndomly generated DAGs with average edge strength β= 0.5(1000 replications).\\nIn summary, our simulation study validates that our proposed confidence regions based on the\\ndual likelihood successfully pick up on the direction and the numerical size of the total causal\\neffect while correctly quantifying the remaining uncertainty in structure as well as effect size. Fur-\\nthermore, the computation times of our proposed confidence regions, computed with the proposed\\nbottom-up procedure, are significantly lower than the competition. Here, we immensely benefit\\nfrom the available closed-form solution due to employing dual likelihood. Especially under high\\nstructure uncertainty, avoiding repeated numerical optimization algorithms is crucial in order to\\ncompute the confidence regions in a reasonable time.\\n1111\\nSTRIEDER DRTON\\nTRUE EFFECT NO TRUE EFFECT\\n3 6 9 123 6 9 121e−011e+011e+03\\ndimensiontime in sec (log scale)LRT\\nDualLRT\\nsparse\\ndense\\nFigure 3: Mean computation times of 95%-confidence regions for the total causal effect in ran-\\ndomly generated DAGs with average edge strength β= 0.1(1000 replications).\\n5. Conclusion\\nIn this article, we address the important problem of rigorously accounting for uncertainty in causal\\ninference when the causal structure itself has to be learned from data. We provide a closed-form\\nsolution for constructing confidence regions for the total causal effect that captures structure un-\\ncertainty as well as uncertainty about the numerical size of the effect. The confidence regions are\\ndeveloped for the concrete context of linear SCMs with equal error variances, where the under-\\nlying assumption of homoscedasticity across all interacting variables renders the causal structure\\nidentifiable. Thus, causal inference of the total causal effect without knowledge of the underlying\\nstructure is a well-defined task. An interesting conclusion of our work is that even in this spe-\\ncialized setting, we already observe high levels of uncertainty about causal directions and size of\\neffects, which highlights the importance of methods that properly account for structure uncertainty\\nin causal inference.\\nOne thing to note is that our general approach of leveraging test inversions of joint tests for\\ncausal structure and effect size is generalizable to other settings. In particular, if one deals with\\nparametric models for which the causal DAG is identifiable, then likelihood ratio tests may be de-\\nployed with the same stochastic approximation strategies as in this paper, and we anticipate that the\\nmatrix inversion interplay between direct and total effects that is behind our use of dual likelihood\\ncan be similarly exploited.\\nWhile unique structure identifiability is required in order to consistently resolve uncertainty\\nabout nonzero causal effects (e.g., when facing full Markov equivalence in linear Gaussian mod-\\nels without variance assumption, the confidence region would always include zero), our frame-\\nwork could in principle be adjusted to target all effects that correspond to graphs within a Markov\\nequivalence class. However, in cases where the causal structure is merely identifiable up to some\\nfaithfulness-type assumption, more research needs to be done to fully understand which causal ef-\\nfects are entailed by a given (possibly unfaithful) distribution.\\n1212\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nThe observed reciprocal correspondence between dual likelihood with total effects and classi-\\ncal likelihood with direct effects could be exploited for other causal inference tasks. The idea is\\nto leverage tools developed for direct effects and classical likelihood to causal inference results for\\ntotal effects via the dual likelihood. In our simulation study, the differences in performance and ex-\\nplanatory power that stem from employing dual likelihood ratio tests instead of classical likelihood\\nratio tests are negligible and heavily outweighed by the significantly reduced computation times due\\nto the available closed-form solution.\\nFinally, given the fast superexponential growth of the number of possible causal structures with\\nthe dimension of the system, it is essential to quickly reject implausible orderings and reduce the\\nsearch space in order to compute confidence regions that account for uncertainty over all struc-\\ntures. The introduced computational shortcuts lead to a bottom-up procedure that, starting from\\nsink nodes, recursively reduces the search space by immediately rejecting implausible partial order-\\nings. In contrast, using the classical likelihood leads to a top-down procedure that starts with source\\nnodes. Cleverly alternating between both procedures in a first step to reduce the search space might\\neven further decrease the computation times of our proposed confidence regions.\\nAcknowledgments\\nThis project has received funding from the European Research Council (ERC) under the European\\nUnion’s Horizon 2020 research and innovation programme (grant agreement No. 83818). Further,\\nthis work has been funded by the German Federal Ministry of Education and Research and the\\nBavarian State Ministry for Science and the Arts. The authors of this work take full responsibility\\nfor its content.\\nReferences\\nLawrence D. Brown. Fundamentals of statistical exponential families with applications in statisti-\\ncal decision theory , volume 9 of Institute of Mathematical Statistics Lecture Notes—Monograph\\nSeries . Institute of Mathematical Statistics, Hayward, CA, 1986.\\nGeorge Casella and Roger L. Berger. Statistical inference . The Wadsworth & Brooks/Cole Statis-\\ntics/Probability Series. Wadsworth & Brooks/Cole Advanced Books & Software, Pacific Grove,\\nCA, 1990.\\nWenyu Chen, Mathias Drton, and Y . Samuel Wang. On causal discovery with an equal-variance\\nassumption. Biometrika , 106(4):973–980, 2019.\\nMathias Drton. Likelihood ratio tests and singularities. Ann. Statist. , 37(2):979–1012, 2009.\\nAsish Ghoshal and Jean Honorio. Learning linear structural equation models in polynomial time\\nand sample complexity. In Proceedings of the Twenty-First International Conference on Artificial\\nIntelligence and Statistics , volume 84, pages 1466–1475. PMLR, 09–11 Apr 2018.\\nG¨oran Kauermann. On a dualization of graphical Gaussian models. Scand. J. Statist. , 23(1):105–\\n116, 1996.\\n1313\\nSTRIEDER DRTON\\nMarloes Maathuis, Mathias Drton, Steffen Lauritzen, and Martin Wainwright, editors. Handbook\\nof graphical models . Chapman & Hall/CRC Handbooks of Modern Statistical Methods. CRC\\nPress, Boca Raton, FL, 2019.\\nJudea Pearl. Causality . Cambridge University Press, Cambridge, second edition, 2009. Models,\\nreasoning, and inference.\\nJonas Peters and Peter B ¨uhlmann. Identifiability of Gaussian structural equation models with equal\\nerror variances. Biometrika , 101(1):219–228, 2014.\\nJonas Peters, Dominik Janzing, and Bernhard Sch ¨olkopf. Elements of causal inference . Adaptive\\nComputation and Machine Learning. MIT Press, Cambridge, MA, 2017.\\nPeter Spirtes, Clark Glymour, and Richard Scheines. Causation, prediction, and search . Adaptive\\nComputation and Machine Learning. MIT Press, Cambridge, MA, 2000.\\nDavid Strieder and Mathias Drton. Confidence in causal inference under structure uncertainty in\\nlinear causal models with equal variances. J. Causal Inference , 11(1), 2023.\\nDavid Strieder, Tobias Freidling, Stefan Haffner, and Mathias Drton. Confidence in causal discovery\\nwith linear causal models. In Proceedings of the Thirty-Seventh Conference on Uncertainty in\\nArtificial Intelligence. UAI’21 , volume 161, pages 1217–1226. PMLR, 27–30 Jul 2021.\\n1414\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nAppendix A. Additional Simulation Results\\nIn this section, we present additional results of our simulation study. The data generation process\\nand general simulation setup are outlined in Section 4.2. Table 1 shows the observed coverage\\nprobabilities for 10-dimensional graphs. Both methods seem to be conservative and achieve the\\ndesired coverage frequency. Considering that we employ critical values based on an upper bound as\\nwell as the theory of intersection union tests for the arising testing problem, it is not surprising that\\nthe resulting confidence regions are conservative. Further, note that under high structure uncertainty,\\nit is not possible to compute the competitor LRT in a reasonable time, which we denoted with NA.\\nAs an additional performance measure, in Figure 4, we compare the proportions of times zero\\nis included in the confidence regions when there is a true nonzero effect. The inclusion of zero in\\nthe confidence regions reflects the remaining uncertainty about the existence of the effect. We show\\nthe results for d= 10 andβ= 0.5against the sample size nas well as for d= 10 and sample\\nsizen= 1000 against the average direct effect strength β. In terms of performance, we observe\\nno significant differences. However, we note again that for high structure uncertainty, which is the\\ncase for low average direct effect strength β, it is not possible to compute the competitor LRT in a\\nreasonable time.\\nFurthermore, with practical applications in mind, Figure 5 investigates the robustness of the\\nmethods towards small deviations from equal error variances. Here, to generate data, we sample\\nthe error variances uniformly from [1−0.5v,1 + 0 .5v], where vindicates the degree of deviation\\nfrom homoscedasticity across all variables. We show the empirical coverage probabilities for d=\\n10, β= 0.5, and sample size n= 1000 against the degree of deviation v. Once again, we only\\nobserve negligible differences, and both methods indicate some robustness to small deviations from\\nequal error variances.\\nFinally, to further explore aspects of model misspecification, we also investigate the robustness\\nof the methods towards deviations from linear relations. We generate data as outlined before, how-\\never, with an increasing emphasis on an additional quadratic dependence structure via the relation\\nXj=P\\ni∈p(j)βi((1+3 v)Xi+0.02vX2\\ni)+εj, for all j= 1, . . . , d . Thus, vindicates the degree of\\ndeviation from linearity. The scaling ensures similar magnitudes of true causal effects across all in-\\nvestigated simulation settings. Note that for nonlinear relations, generally, the true total causal effect\\nis not given by a single parameter but rather by a functional relation. However, when applying linear\\nmodels it is natural to consider as a parameter of interest the slope parameter determining the best\\nlinear approximation within the true causal structure. In Figure 6, we consider this ‘pseudo-linear’\\ntotal effect and show the empirical coverage probabilities for d= 10 , β= 0.5, and sample size\\nn= 1000 against the degree of deviation v. We observe that even under nonlinearity, the methods\\npick up on the direction of the causal relation, and thus, for no causal effect, zero is always covered\\nby the confidence intervals. Note that in the considered nonlinear additive equal variance setting,\\nthe causal ordering is still implied by ordering conditional variances. Further, the performance dif-\\nferences between both methods are negligible, and for nonzero effects, both methods indicate some\\nrobustness to small deviations from linearity.\\n1515\\nSTRIEDER DRTON\\nTable 1: Empirical coverage of 95%-confidence regions for the total causal effect in randomly gen-\\nerated 10-dim. DAGs ( 1000 replications).\\nTRUE EFFECT NO TRUE EFFECT\\nSPARSE DENSE SPARSE DENSE\\nmethod n\\\\β 0.1 0.5 0.1 0.5 0.1 0.5 0.1 0.5\\nDualLRT500 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\\n1000 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00\\n2000 1.00 0.99 0.99 1.00 1.00 1.00 1.00 1.00\\nLRT500 NA 0.99 NA 1.00 NA 1.00 NA 1.00\\n1000 NA 1.00 NA 1.00 NA 1.00 NA 1.00\\n2000 NA 1.00 NA 1.00 NA 1.00 NA 1.00\\n0.00.10.20.30.4\\n500 1000 1500 2000\\nsample sizezero containedLRT\\nDualLRT\\nsparse\\ndense\\n0.000.250.500.751.00\\n0.00.20.40.6\\nedge weight\\nFigure 4: Proportion of times zero contained in 95%-confidence regions for the total causal effect\\nin randomly generated 10-dim. DAGs with true non-zero effect (1000 replications).\\n1616\\nDUAL LIKELIHOOD FOR CAUSAL INFERENCE UNDER STRUCTURE UNCERTAINTY\\nTRUE EFFECT NO TRUE EFFECT\\n0.0 0.5 1.0 1.5 0.0 0.5 1.0 1.50.000.250.500.751.00\\ndeviation from equal error variancesempirical coverageLRT\\nDualLRT\\nsparse\\ndense\\nFigure 5: Empirical coverage of 95%-confidence regions for the total causal effect in randomly\\ngenerated 10-dim. DAGs under departure from equal error variances (1000 replications).\\nTRUE EFFECT NO TRUE EFFECT\\n0.00.20.40.60.80.00.20.40.60.80.000.250.500.751.00\\ndeviation from linearityempirical coverageLRT\\nDualLRT\\nsparse\\ndense\\nFigure 6: Empirical coverage of 95%-confidence regions for the total causal effect in randomly\\ngenerated 10-dim. DAGs under departure from linearity (1000 replications).\\n1717', metadata={'source': 'strieder24a.pdf'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use an OpenAI default embedding model\n",
        "# Note the code in this example does not preserve privacy\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# LangChain provides API functions to interact with FAISS\n",
        "\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "# We create a 'retriever' that knows how to interact with our vector database using an augmented context\n",
        "# We could construct the retriever ourselves from first principles but it's tedious\n",
        "# Instead we'll use LangChain to create a retriever for our vector database\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"search_state_of_union\",\n",
        "    \"Searches and returns documents regarding the state-of-the-union.\"\n",
        ")\n",
        "tools = [tool]\n",
        "\n",
        "# We wrap an LLM (here OpenAI) with a conversational interface that can process augmented requests\n",
        "# LangChain provides an API to interact with chat models\n",
        "\n",
        "llm = ChatOpenAI(temperature = 0)\n",
        "agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=True)\n",
        "\n",
        "input = \"what is test inversion?\"\n",
        "result = agent_executor.invoke({\"input\": input})\n",
        "\n",
        "# Response from the model\n",
        "\n",
        "input = \"What is dual likelihood?\"\n",
        "result = agent_executor.invoke({\"input\": input})\n",
        "\n",
        "# Response from the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "VpZ2PF_r2kjy",
        "outputId": "bef109c8-190b-42bb-e117-641a37ccf088"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-987d0f95fd9f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# LangChain provides API functions to interact with FAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# We create a 'retriever' that knows how to interact with our vector database using an augmented context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \"\"\"\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         return cls.__from(\n\u001b[1;32m    932\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m#       than the maximum context and use length-safe embedding function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_len_safe_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     async def aembed_documents(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36m_get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mbatched_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             response = self.client.create(\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_chunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invocation_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         )\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 922\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    923\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    999\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    999\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    }
  ]
}